{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqqwgc7T6Nhdg18pz2OdQh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsf4K8hImVJ3","executionInfo":{"status":"ok","timestamp":1763961286823,"user_tz":-540,"elapsed":85,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"6a43b198-fe0d-4a44-ad3b-781db48a5056"},"outputs":[{"output_type":"stream","name":"stdout","text":["numpy 버전: 2.0.2\n","matplotlib 버전: 3.10.0\n","tiktoken 버전: 0.12.0\n","torch 버전: 2.9.0+cu126\n","tqdm 버전: 4.67.1\n","tensorflow 버전: 2.19.0\n"]}],"source":["from importlib.metadata import version\n","\n","pkgs = [\n","    \"numpy\",       # 파이토치와 텐서플로 의존성\n","    \"matplotlib\",  # 그래프 라이브러리\n","    \"tiktoken\",    # 토크나이저b\n","    \"torch\",       # 딥러닝 라이브러리\n","    \"tqdm\",        # 진행 표시줄\n","    \"tensorflow\",  # OpenAI에서 사전 훈련된 가중치를 로드하기 위해\n","]\n","for p in pkgs:\n","    print(f\"{p} 버전: {version(p)}\")"]},{"cell_type":"code","source":["import json\n","import os\n","import requests\n","\n","\n","def download_and_load_file(file_path, url):\n","    if not os.path.exists(file_path):\n","        response = requests.get(url, timeout=30)\n","        response.raise_for_status()\n","        text_data = response.text\n","        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","            file.write(text_data)\n","\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        data = json.load(file)\n","\n","    return data\n","\n","file_path = \"instruction-data.json\"\n","url = (\n","    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n","    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",")\n","\n","data = download_and_load_file(file_path, url)\n","print(\"샘플 개수:\", len(data))\n","\n","# 책과 다르다 urllib는 VPN을 사용하는 경우 문제가 있을 수 있음 책코드는 책 참고"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yP6giJmhmXyZ","executionInfo":{"status":"ok","timestamp":1763961287044,"user_tz":-540,"elapsed":220,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"06d58fa4-653a-40c1-a5a0-0373fb57255c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["샘플 개수: 1100\n"]}]},{"cell_type":"code","source":["print(\"샘플 예시:\\n\", data[50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AstpU3mcnHLS","executionInfo":{"status":"ok","timestamp":1763961287060,"user_tz":-540,"elapsed":13,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e0823ba5-489f-4696-adc3-2172dc621ca6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["샘플 예시:\n"," {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"]}]},{"cell_type":"code","source":["print(\"다른 샘플:\\n\", data[999])"],"metadata":{"id":"SITMcOfupOwd","executionInfo":{"status":"ok","timestamp":1763961287064,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"649b6032-85f0-46bd-bb05-c5dffd6cfa93","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["다른 샘플:\n"," {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"]}]},{"cell_type":"code","source":["def format_input(entry):\n","    instruction_text = (\n","        f\"Below is an instruction that describes a task. \"\n","        f\"Write a response that appropriately completes the request.\"\n","        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n","    )\n","\n","    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n","\n","    return instruction_text + input_text"],"metadata":{"id":"recmREXipQRB","executionInfo":{"status":"ok","timestamp":1763961287073,"user_tz":-540,"elapsed":8,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model_input = format_input(data[50])\n","desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n","\n","print(model_input + desired_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1x6yklY3kQ6F","executionInfo":{"status":"ok","timestamp":1763961287080,"user_tz":-540,"elapsed":6,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"1ba281ae-84a7-4b83-f1e2-35de2812ca49"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Identify the correct spelling of the following word.\n","\n","### Input:\n","Ocassion\n","\n","### Response:\n","The correct spelling is 'Occasion.'\n"]}]},{"cell_type":"code","source":["model_input = format_input(data[999])\n","desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n","\n","print(model_input + desired_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOrXv27ake-V","executionInfo":{"status":"ok","timestamp":1763961287126,"user_tz":-540,"elapsed":36,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"2756e38d-44ab-4963-8b21-798d61588fb3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","What is an antonym of 'complicated'?\n","\n","### Response:\n","An antonym of 'complicated' is 'simple'.\n"]}]},{"cell_type":"code","source":["train_portion = int(len(data) * 0.85) # 훈련을 위한 85%\n","test_portion = int(len(data) * 0.1) # 테스트을 위한 10%\n","val_portion = len(data) - train_portion - test_portion # 나머지 5%는 검증용\n","\n","train_data = data[:train_portion]\n","test_data = data[train_portion:train_portion + test_portion]\n","val_data = data[train_portion + test_portion:]"],"metadata":{"id":"F3OE2wwBksF0","executionInfo":{"status":"ok","timestamp":1763961287128,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(\"훈련 세트 길이:\", len(train_data))\n","print(\"검증 세트 길이:\", len(val_data))\n","print(\"테스트 세트 길이:\", len(test_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bgNpqoblLNZ","executionInfo":{"status":"ok","timestamp":1763961287132,"user_tz":-540,"elapsed":4,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"7c9199b5-dc56-49c7-cede-6dcd17d6220d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 세트 길이: 935\n","검증 세트 길이: 55\n","테스트 세트 길이: 110\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class InstructionDataset(Dataset):\n","  def __init__(self, data, tokenizer):\n","    self.data = data\n","\n","    # 텍스트 토큰화\n","    self.encoded_texts = []\n","    for entry in data:\n","      instruction_plus_input = format_input(entry)\n","      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n","      full_text = instruction_plus_input + response_text\n","      self.encoded_texts.append(\n","          tokenizer.encode(full_text)\n","      )\n","  def __getitem__(self, index):\n","    return self.encoded_texts[index]\n","\n","  def __len__(self):\n","    return len(self.data)"],"metadata":{"id":"kuqsd-MOlNUS","executionInfo":{"status":"ok","timestamp":1763961294340,"user_tz":-540,"elapsed":7207,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvJ-tYaToTxC","executionInfo":{"status":"ok","timestamp":1763961295146,"user_tz":-540,"elapsed":803,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"48cbaf46-2b3f-4606-e92a-8a37a1eefddb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[50256]\n"]}]},{"cell_type":"code","source":["def custom_collate_draft_1(\n","    batch,\n","    pad_token_id=50256,\n","    device=\"cpu\"\n","):\n","  # 배치에서 가장 긴 시퀀스 찾기\n","  # 그리고 최대 길이를 +1씩 증가시켜 아래에서 패딩 토큰을 하나 추가\n","  batch_max_length = max(len(item)+1 for item in batch)\n","\n","  # 입력 패딩 및 준비\n","  inputs_lst = []\n","\n","  for item in batch:\n","    new_item = item.copy()\n","    # <|endoftext|> 토큰 추가\n","    new_item += [pad_token_id]\n","    # batch_max_length까지 시퀀스 패딩\n","    padded = (\n","        new_item + [pad_token_id] * (batch_max_length - len(new_item))\n","    )\n","    # padded[:-1]를 통해 batch_max_lenth의 +1 설정을 통해 추가된\n","    # 추가 패딩 토큰을 제거\n","    # (추가 패딩 토큰은 이후 코드에서 관련이 있다)\n","    inputs = torch.tensor(padded[:-1])\n","    inputs_lst.append(inputs)\n","\n","  # 입력 리스트를 텐서로 변환하고 타깃 장치로 전송\n","  inputs_tensor = torch.stack(inputs_lst).to(device)\n","  return inputs_tensor"],"metadata":{"id":"Cpbq0rjxo6Hk","executionInfo":{"status":"ok","timestamp":1763961295165,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["inputs_1 = [0,1,2,3,4]\n","inputs_2 = [5,6]\n","inputs_3 = [7,8,9]\n","\n","batch = (\n","    inputs_1,\n","    inputs_2,\n","    inputs_3,\n",")\n","\n","print(custom_collate_draft_1(batch))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bisPLxRhqb47","executionInfo":{"status":"ok","timestamp":1763961295260,"user_tz":-540,"elapsed":94,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"6b95a791-0314-43b5-9574-3999b0182f10"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,     3,     4],\n","        [    5,     6, 50256, 50256, 50256],\n","        [    7,     8,     9, 50256, 50256]])\n"]}]},{"cell_type":"code","source":["def custom_collate_draft_2(\n","    batch,\n","    pad_token_id=50256,\n","    device=\"cpu\"\n","):\n","  # 배치에서 가장 긴 시퀀스 찾기\n","  batch_max_length = max(len(item) + 1 for item in batch)\n","\n","  # 입력 및 타깃 준비\n","  inputs_lst, targets_lst = [], []\n","\n","  for item in batch:\n","    new_item = item.copy()\n","    # <|endoftext|> 토큰 추가\n","    new_item += [pad_token_id]\n","    # 시퀀스를 max_length까지 패딩\n","    padded = (\n","        new_item + [pad_token_id] * (batch_max_length - len(new_item))\n","    )\n","    inputs = torch.tensor(padded[:-1]) # 입력을 위해 마지막 토큰 자르기\n","    targets = torch.tensor(padded[1:]) # 타깃을 위해 오른쪽으로 +1 이동\n","    inputs_lst.append(inputs)\n","    targets_lst.append(targets)\n","\n","  # 입력 리스트를 텐서로 변환하고 타깃 장치로 전송\n","  inputs_tensor = torch.stack(inputs_lst).to(device)\n","  targets_tensor = torch.stack(targets_lst).to(device)\n","  return inputs_tensor, targets_tensor"],"metadata":{"id":"vZhWMWnkrO9X","executionInfo":{"status":"ok","timestamp":1763961295284,"user_tz":-540,"elapsed":22,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["inputs, targets = custom_collate_draft_2(batch)\n","print(inputs)\n","print(targets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5umlI-zsYwN","executionInfo":{"status":"ok","timestamp":1763961295295,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"1f155e20-d610-4555-b1fb-19a4490d0830"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,     3,     4],\n","        [    5,     6, 50256, 50256, 50256],\n","        [    7,     8,     9, 50256, 50256]])\n","tensor([[    1,     2,     3,     4, 50256],\n","        [    6, 50256, 50256, 50256, 50256],\n","        [    8,     9, 50256, 50256, 50256]])\n"]}]},{"cell_type":"code","source":["def custom_collate_fn(\n","    batch,\n","    pad_token_id=50256,\n","    ignore_index=-100,\n","    allowed_max_length=None,\n","    device=\"cpu\"\n","):\n","  # 배치에서 가장 긴 시퀀스 찾기\n","  batch_max_length = max(len(item) + 1 for item in batch)\n","\n","  # 입력과 타깃 패딩 및 준비\n","  inputs_lst, targets_lst = [], []\n","\n","  for item in batch:\n","    new_item = item.copy()\n","    # <|endoftext|> 토큰 추가\n","    new_item += [pad_token_id]\n","    # 시퀀스를 max_length까지 패딩\n","    padded = (\n","        new_item + [pad_token_id] * (batch_max_length - len(new_item))\n","    )\n","    inputs = torch.tensor(padded[:-1]) # 입력을 위해 마지막 토큰 자르기\n","    targets = torch.tensor(padded[1:]) # 목표를 위해 오른쪽으로 +1 이동\n","\n","    # 새로 추가: 목표에서 첫 번째 패딩 토큰을 제외한 모든 토큰을 ignore_index로 바꾸기\n","    mask = targets == pad_token_id\n","    indices = torch.nonzero(mask).squeeze()\n","    if indices.numel() > 1:\n","      targets[indices[1:]] = ignore_index\n","\n","    # 새로 추가: 최대 시퀀스 길이로 자르기 (선택사항)\n","    if allowed_max_length is not None:\n","      inputs = inputs[:allowed_max_length]\n","      targets = targets[:allowed_max_length]\n","\n","    inputs_lst.append(inputs)\n","    targets_lst.append(targets)\n","\n","  # 입력 및 타깃 리스트를 텐서로 변환하고 타깃 장치로 전송\n","  inputs_tensor = torch.stack(inputs_lst).to(device)\n","  targets_tensor = torch.stack(targets_lst).to(device)\n","\n","  return inputs_tensor, targets_tensor"],"metadata":{"id":"pF3jBToAsd2l","executionInfo":{"status":"ok","timestamp":1763961295309,"user_tz":-540,"elapsed":14,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["inputs, targets = custom_collate_fn(batch)\n","print(inputs)\n","print(targets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQVMX7geuopr","executionInfo":{"status":"ok","timestamp":1763961295376,"user_tz":-540,"elapsed":68,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"282e7089-bce0-47ee-b55f-f4bd9bc12245"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,     3,     4],\n","        [    5,     6, 50256, 50256, 50256],\n","        [    7,     8,     9, 50256, 50256]])\n","tensor([[    1,     2,     3,     4, 50256],\n","        [    6, 50256,  -100,  -100,  -100],\n","        [    8,     9, 50256,  -100,  -100]])\n"]}]},{"cell_type":"code","source":["logits_1 = torch.tensor(\n","    [\n","        [-1.0, 1.0], # 첫 번째 훈련 샘플\n","        [-0.5, 1.5], # 두 번째 훈련 샘플\n","    ]\n",")\n","targets_1 = torch.tensor([0,1])\n","\n","loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n","print(loss_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZEA0jIdusuA","executionInfo":{"status":"ok","timestamp":1763961295445,"user_tz":-540,"elapsed":69,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"cc4b922f-3dba-4a89-d07d-fe3535d48ade"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.1269)\n"]}]},{"cell_type":"code","source":["logits_2 = torch.tensor(\n","    [\n","        [-1.0, 1.0], # 첫 번째 훈련 샘플\n","        [-0.5, 1.5], # 두 번째 훈련 샘플\n","        [-0.5, 1.5], # 세 번째 훈련 샘플\n","    ]\n",")\n","targets_2 = torch.tensor([0,1, 1])\n","\n","loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n","print(loss_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ncwbynugvotn","executionInfo":{"status":"ok","timestamp":1763961295519,"user_tz":-540,"elapsed":75,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"54fa577e-3a88-42f6-ad56-999e0711b57f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.7936)\n"]}]},{"cell_type":"code","source":["targets_3 = torch.tensor([0, 1, -100])\n","\n","loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n","print(loss_3)\n","print(\"loss_1 == loss_3:\", loss_1 == loss_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcC23Cu-vzZg","executionInfo":{"status":"ok","timestamp":1763961295519,"user_tz":-540,"elapsed":5,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"a1253286-f2e9-48e3-f4bb-0b0aaa315a40"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.1269)\n","loss_1 == loss_3: tensor(True)\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 참고:\n","# 다음 줄의 주석을 제거하면 코드가 애플 실리콘 칩에서 실행될 수 있습니다.\n","# 애플 CPU보다 훨씬 빠릅니다(M3 맥북 에어에서 측정한 결과).\n","# 하지만 결과 손실 값이 약간 다를 수 있습니다.\n","\n","#if torch.cuda.is_available():\n","#    device = torch.device(\"cuda\")\n","#elif torch.backends.mps.is_available():\n","#    device = torch.device(\"mps\")\n","#else:\n","#    device = torch.device(\"cpu\")\n","\n","print(\"장치:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VM_FcRVwIN4","executionInfo":{"status":"ok","timestamp":1763961295530,"user_tz":-540,"elapsed":12,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"a1dd42e7-4053-4099-e21e-81728488c380"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["장치: cpu\n"]}]},{"cell_type":"code","source":["from functools import partial\n","\n","customized_collate_fn = partial(\n","    custom_collate_fn,\n","    device=device,\n","    allowed_max_length=1024\n",")"],"metadata":{"id":"QcXVUtNLLsqW","executionInfo":{"status":"ok","timestamp":1763961295531,"user_tz":-540,"elapsed":0,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","num_workers = 0\n","batch_size = 8\n","\n","torch.manual_seed(123)\n","\n","train_dataset = InstructionDataset(train_data, tokenizer)\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    collate_fn=customized_collate_fn,\n","    shuffle=True,\n","    drop_last=True,\n","    num_workers=num_workers\n",")\n","val_dataset = InstructionDataset(val_data, tokenizer)\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    collate_fn=customized_collate_fn,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")\n","test_dataset = InstructionDataset(test_data, tokenizer)\n","test_loader = DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    collate_fn=customized_collate_fn,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")"],"metadata":{"id":"LEO5zz7-MC_X","executionInfo":{"status":"ok","timestamp":1763961295770,"user_tz":-540,"elapsed":238,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(\"훈련 데이터 로더:\")\n","for inputs, targets in train_loader:\n","    print(inputs.shape, targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyyUNBTHM_wA","executionInfo":{"status":"ok","timestamp":1763961296193,"user_tz":-540,"elapsed":421,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"617eb299-091b-45c4-b39b-521778a9f21b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 데이터 로더:\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 73]) torch.Size([8, 73])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 80]) torch.Size([8, 80])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 75]) torch.Size([8, 75])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 77]) torch.Size([8, 77])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 79]) torch.Size([8, 79])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 80]) torch.Size([8, 80])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 91]) torch.Size([8, 91])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 75]) torch.Size([8, 75])\n","torch.Size([8, 89]) torch.Size([8, 89])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 88]) torch.Size([8, 88])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 74]) torch.Size([8, 74])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 75]) torch.Size([8, 75])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 80]) torch.Size([8, 80])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 87]) torch.Size([8, 87])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 57]) torch.Size([8, 57])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 74]) torch.Size([8, 74])\n","torch.Size([8, 80]) torch.Size([8, 80])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 91]) torch.Size([8, 91])\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 80]) torch.Size([8, 80])\n","torch.Size([8, 81]) torch.Size([8, 81])\n","torch.Size([8, 74]) torch.Size([8, 74])\n","torch.Size([8, 82]) torch.Size([8, 82])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 77]) torch.Size([8, 77])\n","torch.Size([8, 91]) torch.Size([8, 91])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 75]) torch.Size([8, 75])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 78]) torch.Size([8, 78])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 74]) torch.Size([8, 74])\n","torch.Size([8, 69]) torch.Size([8, 69])\n"]}]},{"cell_type":"code","source":["print(inputs[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBDIYF9INQ0i","executionInfo":{"status":"ok","timestamp":1763961296206,"user_tz":-540,"elapsed":11,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"23153994-9e5e-4aae-8b6b-0f3e18999ec4"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n","          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n","        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n","          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n","         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n","          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"]}]},{"cell_type":"code","source":["print(targets[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zOo6mzlNm_k","executionInfo":{"status":"ok","timestamp":1763961296217,"user_tz":-540,"elapsed":9,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"7f638416-8cb8-438e-c251-e12d5eff665a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n","         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n","        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n","          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n","          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n","          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n","         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"]}]},{"cell_type":"code","source":["# 코랩의 경우 gpt_download.py와 previous_chapter.py 파일을 다운로드합니다.\n","!wget https://bit.ly/3FQ2wXM -O gpt_download.py\n","!wget https://bit.ly/4egJDdd -O previous_chapters.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zTr1W9FNobW","executionInfo":{"status":"ok","timestamp":1763961296859,"user_tz":-540,"elapsed":635,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"63eff160-2ce0-45bc-89a6-23aa6e02a133"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-24 05:14:56--  https://bit.ly/3FQ2wXM\n","Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n","Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/gpt_download.py [following]\n","--2025-11-24 05:14:56--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/gpt_download.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4687 (4.6K) [text/plain]\n","Saving to: ‘gpt_download.py’\n","\n","gpt_download.py     100%[===================>]   4.58K  --.-KB/s    in 0s      \n","\n","2025-11-24 05:14:56 (35.6 MB/s) - ‘gpt_download.py’ saved [4687/4687]\n","\n","--2025-11-24 05:14:56--  https://bit.ly/4egJDdd\n","Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n","Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/previous_chapters.py [following]\n","--2025-11-24 05:14:56--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/previous_chapters.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 18236 (18K) [text/plain]\n","Saving to: ‘previous_chapters.py’\n","\n","previous_chapters.p 100%[===================>]  17.81K  --.-KB/s    in 0.001s  \n","\n","2025-11-24 05:14:56 (13.3 MB/s) - ‘previous_chapters.py’ saved [18236/18236]\n","\n"]}]},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","from previous_chapters import GPTModel, load_weights_into_gpt\n","\n","\n","BASE_CONFIG = {\n","    \"vocab_size\": 50257,     # 어휘사전 크기\n","    \"context_length\": 1024,  # 문맥 길이\n","    \"drop_rate\": 0.0,        # 드롭아웃 비율\n","    \"qkv_bias\": True         # 쿼리-키-값 편향\n","}\n","\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","CHOOSE_MODEL = \"gpt2-medium (355M)\"\n","\n","BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n","\n","model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n","settings, params = download_and_load_gpt2(\n","    model_size=model_size,\n","    models_dir=\"gpt2\"\n",")\n","\n","model = GPTModel(BASE_CONFIG)\n","load_weights_into_gpt(model, params)\n","model.eval();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGEHxv-YODR1","executionInfo":{"status":"ok","timestamp":1763961332640,"user_tz":-540,"elapsed":35777,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e3c4dfdb-2345-4ffd-b1f4-da024cd12aab"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["File already exists and is up-to-date: gpt2/355M/checkpoint\n","File already exists and is up-to-date: gpt2/355M/encoder.json\n","File already exists and is up-to-date: gpt2/355M/hparams.json\n","File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n","File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n","File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n","File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"]}]},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","input_text = format_input(val_data[0])\n","print(input_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bk-Q0VcoONuz","executionInfo":{"status":"ok","timestamp":1763961332663,"user_tz":-540,"elapsed":21,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e9eb9e3c-7568-4b75-f834-739ee5002f92"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"]}]},{"cell_type":"code","source":["from previous_chapters import (generate, text_to_token_ids, token_ids_to_text)\n","\n","token_ids = generate(\n","    model=model,\n","    idx=text_to_token_ids(input_text,tokenizer),\n","    max_new_tokens=35,\n","    context_size=BASE_CONFIG[\"context_length\"],\n","    eos_id=50256,\n",")\n","generated_text = token_ids_to_text(token_ids, tokenizer)"],"metadata":{"id":"wrDXyYquOt51","executionInfo":{"status":"ok","timestamp":1763961377999,"user_tz":-540,"elapsed":45335,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["response_text = (\n","    generated_text[len(input_text):]\n","    .replace(\"### Response:\", \"\")\n","    .strip()\n",")\n","print(response_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpbnqJxaPOnJ","executionInfo":{"status":"ok","timestamp":1763961378007,"user_tz":-540,"elapsed":6,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"b8fcb280-2262-4094-843a-8339dd03daac"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["The chef cooks the meal every day.\n","\n","### Instruction:\n","\n","Convert the active sentence to passive: 'The chef cooks the\n"]}]},{"cell_type":"code","source":["from previous_chapters import (\n","    calc_loss_loader,\n","    train_model_simple\n",")"],"metadata":{"id":"pKchU4e7PivQ","executionInfo":{"status":"ok","timestamp":1763961378007,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["model.to(device)\n","\n","torch.manual_seed(123)\n","\n","with torch.no_grad():\n","    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n","    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n","\n","print(\"훈련 손실:\", train_loss)\n","print(\"검증 손실:\", val_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Ok3P4FGQEzZ","executionInfo":{"status":"ok","timestamp":1763961474091,"user_tz":-540,"elapsed":96085,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"9a269a8a-d9d1-481d-9d05-cd21f792d377"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 손실: 3.8258956909179687\n","검증 손실: 3.7619205951690673\n"]}]},{"cell_type":"code","source":["# Colab 무료 버전으로는 사용 불가능..\n","# 사용 가능한 RAM 부족으로 세션 다운된다\n","\n","# import time\n","\n","# start_time = time.time()\n","\n","# torch.manual_seed(123)\n","\n","# optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n","\n","# num_epochs = 2\n","\n","# train_losses, val_losses, tokens_seen = train_model_simple(\n","#     model, train_loader, val_loader, optimizer, device,\n","#     num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n","#     start_context=format_input(val_data[0]), tokenizer=tokenizer\n","# )\n","\n","# end_time = time.time()\n","# execution_time_minutes = (end_time - start_time) / 60\n","# print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분\")"],"metadata":{"id":"p6HbL8q1QIrt","executionInfo":{"status":"ok","timestamp":1763961474093,"user_tz":-540,"elapsed":23,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# from previous_chapters import plot_losses\n","\n","# epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n","# plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"],"metadata":{"id":"ZmlSSpCZRe4k","executionInfo":{"status":"ok","timestamp":1763961474094,"user_tz":-540,"elapsed":16,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","for entry in test_data[:3]:\n","\n","  input_text = format_input(entry)\n","\n","  token_ids = generate(\n","      model=model,\n","      idx=text_to_token_ids(input_text, tokenizer).to(device),\n","      max_new_tokens=256,\n","      context_size=BASE_CONFIG[\"context_length\"],\n","      eos_id=50256,\n","  )\n","  generated_text = token_ids_to_text(token_ids, tokenizer)\n","  response_text = (\n","      generated_text[len(input_text):]\n","      .replace(\"### Response:\", \"\")\n","      .strip()\n","  )\n","\n","  print(input_text)\n","  print(f\"\\n올바른 응답:\\n>> {entry['output']}\")\n","  print(f\"\\n모델 응답:\\n>> {response_text.strip()}\")\n","  print(\"-------------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDC_wUVSSKJ1","outputId":"48337da5-327c-404a-e65f-ef3c4b612a5c"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Rewrite the sentence using a simile.\n","\n","### Input:\n","The car is very fast.\n","\n","올바른 응답:\n",">> The car is as fast as lightning.\n","\n","모델 응답:\n",">> ### Output:\n","\n","The car is very slow.\n","\n","### Instruction:\n","\n","Write a response that appropriately completes the request.\n","\n","### Input:\n","\n","The car is very fast.\n","\n","### Output:\n","\n","The car is very slow.\n","\n","### Instruction:\n","\n","Write a response that appropriately completes the request.\n","\n","### Input:\n","\n","The car is very fast.\n","\n","### Output:\n","\n","The car is very slow.\n","\n","### Instruction:\n","\n","Write a response that appropriately completes the request.\n","\n","### Input:\n","\n","The car is very fast.\n","\n","### Output:\n","\n","The car is very slow.\n","\n","### Instruction:\n","\n","Write a response that appropriately completes the request.\n","\n","### Input:\n","\n","The car is very fast.\n","\n","### Output:\n","\n","The car is very slow.\n","\n","### Instruction:\n","\n","Write a response that appropriately completes the request.\n","\n","### Input:\n","\n","The car is very fast.\n","\n","### Output:\n","\n","The car is very slow.\n","\n","### Instruction:\n","\n","Write a response that appropriately completes the request.\n","\n","### Input:\n","\n","The car is very fast.\n","\n","### Output\n","-------------------------------------\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n","\n","  input_text = format_input(entry)\n","\n","  token_ids = generate(\n","      model=model,\n","      idx=text_to_token_ids(input_text, tokenizer).to(device),\n","      max_new_tokens=256,\n","      context_size=BASE_CONFIG[\"context_length\"],\n","      eos_id=50256,\n","  )\n","\n","  generated_text = token_ids_to_text(token_ids, tokenizer)\n","  response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n","\n","  test_data[i][\"model_response\"] = response_text\n","\n","with open(\"instruction-data-with.response.json\", \"w\") as file:\n","  json.dump(test_data, file, indent=4) # 미려한 출력을 위해 \"indent\" 사용"],"metadata":{"id":"pCuPSS27lpgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_data[0])"],"metadata":{"id":"EjmKlXwNnWsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","\n","file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n","torch.save(model.state_dict(), file_name)\n","print(f\"모델이 {file_name}에 저장되었습니다.\")\n","\n","# 모델 로드 방법:\n","# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"],"metadata":{"id":"pX72wdI0n2xX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C1a2V_yPn7-F"},"execution_count":null,"outputs":[]}]}