{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWWp0ZqH25l2C/9NkHPbxg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLy2CaE2OM3v","executionInfo":{"status":"ok","timestamp":1762401976969,"user_tz":-540,"elapsed":14,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"85d7f48a-2371-4932-9c4a-478b03fe0db0"},"outputs":[{"output_type":"stream","name":"stdout","text":["파이토치 버전: 2.8.0+cu126\n"]}],"source":["from importlib.metadata import version\n","\n","print(\"파이토치 버전:\", version(\"torch\"))"]},{"cell_type":"code","source":["import torch\n","\n","inputs = torch.tensor(\n","    [\n","        [0.43, 0.15, 0.89], # Your.   (x^1)\n","        [0.55, 0.87, 0.66], # journey (x^2)\n","        [0.57, 0.85, 0.64], # starts. (x^3)\n","        [0.22, 0.58, 0.33], # with.   (x^4)\n","        [0.77, 0.25, 0.10], # one.    (x^5)\n","        [0.05, 0.80, 0.55], # stop.   (x^6)\n","    ]\n","\n",")"],"metadata":{"id":"3snumDEuOSbU","executionInfo":{"status":"ok","timestamp":1762401976989,"user_tz":-540,"elapsed":19,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["query = inputs[1]\n","\n","attn_scores_2 = torch.empty(inputs.shape[0])\n","for i, x_i in enumerate(inputs):\n","  attn_scores_2[i] = torch.dot(x_i, query) # 점곱 (1차원 벡터이므로 전치가 필요 없다.\n","\n","print(attn_scores_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5EFW630UBDo","executionInfo":{"status":"ok","timestamp":1762401977039,"user_tz":-540,"elapsed":49,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"8c3ba48f-3acb-472f-8c7c-d6360f937e47"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"]}]},{"cell_type":"code","source":["res = 0.\n","\n","for idx, element in enumerate(inputs[0]):\n","  res += inputs[0][idx] * query[idx]\n","\n","print(res)\n","print(torch.dot(inputs[0], query))"],"metadata":{"id":"PMi-amQIUjGA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762401977040,"user_tz":-540,"elapsed":6,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"d763e08c-c81e-4f7b-b7b3-deecaf2a5f12"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.9544)\n","tensor(0.9544)\n"]}]},{"cell_type":"code","source":["attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n","\n","print(\"어텐션 가중치:\", attn_weights_2_tmp)\n","print(\"합:\", attn_weights_2_tmp.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFABzxthh5dT","executionInfo":{"status":"ok","timestamp":1762401977040,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"75bc655f-07b5-4db6-90b2-ea26f80d738e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["어텐션 가중치: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n","합: tensor(1.0000)\n"]}]},{"cell_type":"code","source":["def softmax_naive(x):\n","  return torch.exp(x) / torch.exp(x).sum(dim=0)\n","\n","attn_weights2_naive = softmax_naive(attn_scores_2)\n","\n","print(\"어텐션 가중치:\", attn_weights2_naive)\n","print(\"합:\", attn_weights2_naive.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2CNT94fiZ3b","executionInfo":{"status":"ok","timestamp":1762401977042,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"50f60c2f-5f36-4962-b32a-dfd834ac93d8"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["어텐션 가중치: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n","합: tensor(1.)\n"]}]},{"cell_type":"code","source":["attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n","\n","print(\"어텐션 가중치:\", attn_weights_2)\n","print(\"합:\", attn_weights_2.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnTcyZcVi6Wh","executionInfo":{"status":"ok","timestamp":1762401977046,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e725c8c5-f96d-4fdf-e5a5-d718ce9e984b"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["어텐션 가중치: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n","합: tensor(1.)\n"]}]},{"cell_type":"code","source":["query = inputs[1]\n","\n","context_vec_2 = torch.zeros(query.shape)\n","for i, x_i in enumerate(inputs):\n","  context_vec_2 += attn_weights_2[i]*x_i\n","\n","print(context_vec_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nL5bz2V4jYFV","executionInfo":{"status":"ok","timestamp":1762401977060,"user_tz":-540,"elapsed":13,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"1e472abb-3410-40bb-9057-9edee30c795b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.4419, 0.6515, 0.5683])\n"]}]},{"cell_type":"code","source":["attn_scores = torch.empty(6,6)\n","\n","for i, x_i in enumerate(inputs):\n","  for j, x_j in enumerate(inputs):\n","    attn_scores[i, j] = torch.dot(x_i, x_j)\n","\n","print(attn_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBgjSzrOkRmq","executionInfo":{"status":"ok","timestamp":1762401977091,"user_tz":-540,"elapsed":30,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"9459da54-6050-45ec-98c0-605c6cb421b5"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n","        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n","        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n","        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n","        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n","        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"]}]},{"cell_type":"code","source":["attn_scores = inputs @ inputs.T\n","print(attn_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05pZ052lk342","executionInfo":{"status":"ok","timestamp":1762401977107,"user_tz":-540,"elapsed":15,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"70b0b5c0-4bf8-4482-c827-6d9856eab8ae"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n","        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n","        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n","        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n","        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n","        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"]}]},{"cell_type":"code","source":["attn_weights = torch.softmax(attn_scores, dim=-1)\n","print(attn_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH0Ksk1TlIn4","executionInfo":{"status":"ok","timestamp":1762401977108,"user_tz":-540,"elapsed":13,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"3a074f98-2db0-475e-c938-5dcc09c51e66"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n","        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n","        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n","        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n","        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n","        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"]}]},{"cell_type":"code","source":["row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n","print(\"두 번째 행의 합:\", row_2_sum)\n","\n","print(\"모든 행의 합:\", attn_weights.sum(dim=-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9iCMsmAmE5u","executionInfo":{"status":"ok","timestamp":1762401977108,"user_tz":-540,"elapsed":11,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"38a55ccb-6c85-4e99-d31e-2853b571ce88"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["두 번째 행의 합: 1.0\n","모든 행의 합: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"]}]},{"cell_type":"code","source":["all_context_vecs = attn_weights @ inputs\n","print(all_context_vecs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5X9KaZ_mQY-","executionInfo":{"status":"ok","timestamp":1762401977110,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"696b0266-9242-4790-90bd-c4fca427435f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4421, 0.5931, 0.5790],\n","        [0.4419, 0.6515, 0.5683],\n","        [0.4431, 0.6496, 0.5671],\n","        [0.4304, 0.6298, 0.5510],\n","        [0.4671, 0.5910, 0.5266],\n","        [0.4177, 0.6503, 0.5645]])\n"]}]},{"cell_type":"code","source":["print(\"이전에 계산한 두 번째 문맥 벡터:\", context_vec_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iioAl-fpmlnf","executionInfo":{"status":"ok","timestamp":1762401977120,"user_tz":-540,"elapsed":10,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"4412af82-4892-4310-aaae-bcf1e81f304f"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["이전에 계산한 두 번째 문맥 벡터: tensor([0.4419, 0.6515, 0.5683])\n"]}]},{"cell_type":"code","source":["x_2 = inputs[1]\n","d_in = inputs.shape[1]\n","d_out = 2"],"metadata":{"id":"yTevJV6em16o","executionInfo":{"status":"ok","timestamp":1762401977282,"user_tz":-540,"elapsed":158,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n","W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n","W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"],"metadata":{"id":"x3OjGfwC3fy0","executionInfo":{"status":"ok","timestamp":1762401977283,"user_tz":-540,"elapsed":8,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["query_2 = x_2 @ W_query\n","key_2 = x_2 @ W_key\n","value_2 = x_2 @ W_value\n","\n","print(query_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pvwvLaX3yw7","executionInfo":{"status":"ok","timestamp":1762401977284,"user_tz":-540,"elapsed":8,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"9cdc06a0-beb7-489f-9869-b01e43984929"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.4306, 1.4551])\n"]}]},{"cell_type":"code","source":["keys = inputs @ W_key\n","values = inputs @ W_value\n","\n","print(\"keys.shape:\", keys.shape)\n","print(\"values.shape:\", values.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Kb9VHsQ4EPv","executionInfo":{"status":"ok","timestamp":1762401977284,"user_tz":-540,"elapsed":5,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"9959cb49-e496-412b-9e82-79adde90a81a"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["keys.shape: torch.Size([6, 2])\n","values.shape: torch.Size([6, 2])\n"]}]},{"cell_type":"code","source":["keys_2 = keys[1]\n","attn_score_22 = query_2.dot(keys_2)\n","print(attn_score_22)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRh3lkBC4Vx7","executionInfo":{"status":"ok","timestamp":1762401977295,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"0b9d0fc0-7bc8-45ce-99a0-9da91b5dc784"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.8524)\n"]}]},{"cell_type":"code","source":["attn_scores_2 = query_2 @ keys.T # 주어진 쿼리에 대한 모든 어텐션 점수\n","print(attn_scores_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Qcyz5424uI4","executionInfo":{"status":"ok","timestamp":1762401977298,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"c7a53c50-c155-40c8-81b5-5f0829216042"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"]}]},{"cell_type":"code","source":["d_k = keys.shape[1]\n","attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n","print(attn_weights_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycneFI_h433Z","executionInfo":{"status":"ok","timestamp":1762401977301,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"880e222f-af09-445c-c65b-ec8bef7957ea"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"]}]},{"cell_type":"code","source":["context_vec_2 = attn_weights_2 @ values\n","print(context_vec_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-nWIYyz5Mp7","executionInfo":{"status":"ok","timestamp":1762401977304,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"5a38083c-4dc0-40df-b3e2-232dacc0b95b"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.3061, 0.8210])\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class SelfAttention_v1(nn.Module):\n","\n","  def __init__(self, d_in, d_out):\n","    super().__init__()\n","    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n","    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n","    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n","\n","  def forward(self, x):\n","    keys = x @ self.W_key\n","    queries = x @ self.W_query\n","    values = x @ self.W_value\n","\n","    attn_scores = queries @ keys.T # omega\n","    attn_weights = torch.softmax(\n","        attn_scores / keys.shape[-1]**0.5, dim=-1\n","    )\n","\n","    context_vec = attn_weights @ values\n","    return context_vec\n","\n","torch.manual_seed(123)\n","sa_v1 = SelfAttention_v1(d_in, d_out)\n","print(sa_v1(inputs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYsomUHK5d-a","executionInfo":{"status":"ok","timestamp":1762401977307,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"c42f73f2-9bf3-47fd-a32f-4c9d59940f81"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2996, 0.8053],\n","        [0.3061, 0.8210],\n","        [0.3058, 0.8203],\n","        [0.2948, 0.7939],\n","        [0.2927, 0.7891],\n","        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"code","source":["class SelfAttention_v2(nn.Module):\n","\n","  def __init__(self, d_in, d_out, qkv_bias=False):\n","    super().__init__()\n","    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","\n","  def forward(self, x):\n","    keys = self.W_key(x)\n","    queries = self.W_query(x)\n","    values = self.W_value(x)\n","\n","    attn_scores = queries @ keys.T # omega\n","    attn_weights = torch.softmax(\n","        attn_scores / keys.shape[-1]**0.5, dim=-1\n","    )\n","\n","    context_vec = attn_weights @ values\n","    return context_vec\n","\n","torch.manual_seed(789)\n","sa_v2 = SelfAttention_v2(d_in, d_out)\n","print(sa_v2(inputs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6En4fDKp6T42","executionInfo":{"status":"ok","timestamp":1762401977309,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"a0626d9e-3e3d-4ebf-88ba-0c6dc8951b81"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.0739,  0.0713],\n","        [-0.0748,  0.0703],\n","        [-0.0749,  0.0702],\n","        [-0.0760,  0.0685],\n","        [-0.0763,  0.0679],\n","        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"code","source":["queries = sa_v2.W_query(inputs)\n","keys = sa_v2.W_key(inputs)\n","attn_scores = queries @ keys.T\n","\n","attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","print(attn_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6eCdmSU9jOs","executionInfo":{"status":"ok","timestamp":1762401977311,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e432ffc2-4f0d-478a-954c-a192b91bd17b"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n","        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n","        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n","        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n","        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n","        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n","       grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"code","source":["context_length = attn_scores.shape[0]\n","mask_simple = torch.tril(torch.ones(context_length, context_length)) # diagonal=-1, triu()\n","print(mask_simple)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMsSpzQf-GWw","executionInfo":{"status":"ok","timestamp":1762401977328,"user_tz":-540,"elapsed":16,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"94af5128-b672-44d4-a2ff-3dc58dd42074"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 0., 0., 0., 0.],\n","        [1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0.],\n","        [1., 1., 1., 1., 1., 0.],\n","        [1., 1., 1., 1., 1., 1.]])\n"]}]},{"cell_type":"code","source":["masked_simple = attn_weights*mask_simple\n","print(masked_simple)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uJrWt2X-H5U","executionInfo":{"status":"ok","timestamp":1762401977329,"user_tz":-540,"elapsed":7,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"11f4cbc5-880b-4009-de53-4e2234b99360"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n","        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n","        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n","        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n","       grad_fn=<MulBackward0>)\n"]}]},{"cell_type":"code","source":["row_sums = masked_simple.sum(dim=-1, keepdim=True)\n","masked_simple_norm = masked_simple / row_sums\n","print(masked_simple_norm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NXFg5rIs-n5t","executionInfo":{"status":"ok","timestamp":1762401977329,"user_tz":-540,"elapsed":4,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"886f47b3-5b94-47b0-bec1-02107ad04bb8"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n","        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n","        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n","        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n","       grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"code","source":["mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n","masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n","print(masked)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvTzLBup_AnP","executionInfo":{"status":"ok","timestamp":1762401977457,"user_tz":-540,"elapsed":129,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"9389881a-0f40-485f-f59e-b7d56e90dd58"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n","        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n","        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n","        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n","        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n","        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n","       grad_fn=<MaskedFillBackward0>)\n"]}]},{"cell_type":"code","source":["attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\n","print(attn_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMg04Jun_YbQ","executionInfo":{"status":"ok","timestamp":1762401977460,"user_tz":-540,"elapsed":4,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e0b416fa-fec3-4e64-ae70-3ec57057efe8"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n","        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n","        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n","        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n","       grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"code","source":["torch.manual_seed(123)\n","dropout = torch.nn.Dropout(0.5) # 50% 드랍아웃 비율\n","example = torch.ones(6,6) # 1로 채워진 행렬을 만든다.\n","\n","print(dropout(example))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-CtauhIh_xtz","executionInfo":{"status":"ok","timestamp":1762401977475,"user_tz":-540,"elapsed":14,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"df1616cf-03e6-44ae-d8dd-cff6f0386f91"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2., 2., 0., 2., 2., 0.],\n","        [0., 0., 0., 2., 0., 2.],\n","        [2., 2., 2., 2., 0., 2.],\n","        [0., 2., 2., 0., 0., 2.],\n","        [0., 2., 0., 2., 0., 2.],\n","        [0., 2., 2., 2., 2., 0.]])\n"]}]},{"cell_type":"code","source":["torch.manual_seed(123)\n","print(dropout(attn_weights))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nGzbKmhAmc7","executionInfo":{"status":"ok","timestamp":1762401977476,"user_tz":-540,"elapsed":7,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"202a6b9a-b35e-4866-c9e3-89930c6ceceb"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n","        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n","       grad_fn=<MulBackward0>)\n"]}]},{"cell_type":"code","source":["batch = torch.stack((inputs, inputs), dim=0)\n","print(batch.shape) # 각각 여섯 개의 토큰으로 구성된 두 개의 입력. 각 토큰의 임베딩 차원은 3이다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfwJErAIAx4Y","executionInfo":{"status":"ok","timestamp":1762401977476,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e89a04d7-d9b6-490d-98ca-4ccbf93f42f0"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 6, 3])\n"]}]},{"cell_type":"code","source":["class CausalAttention(nn.Module):\n","  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n","    super().__init__()\n","    # self.d_out = d_out\n","    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.dropout = nn.Dropout(dropout) # 추가\n","    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # 추가\n","\n","  def forward(self, x):\n","    b, num_tokens, d_in = x.shape # b: 배치 차원\n","    # 입력의 `num_tokens`가 `context_length`를 넘는 경우 마스크 생성에서 오류가 발생\n","    # 실제로는 forward 메서드에 들어괴 전에 LLM이 입력이 `context_length`를\n","    # 넘지 않는지 확인하기 때문에 문제가 되지 않는다.\n","    keys = self.W_key(x)\n","    queries = self.W_query(x)\n","    values = self.W_value(x)\n","\n","    attn_scores = queries @ keys.transpose(1, 2) # 전치\n","    attn_scores.masked_fill( # _ 메서드는 인플레이스 연산\n","        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n","    attn_weights = torch.softmax(\n","        attn_scores / keys.shape[-1]**0.5, dim=-1\n","    )\n","    attn_weights = self.dropout(attn_weights) # 추가\n","\n","    context_vec = attn_weights @ values\n","    return context_vec\n","\n","torch.manual_seed(123)\n","\n","context_length = batch.shape[1]\n","ca = CausalAttention(d_in, d_out, context_length, 0.0)\n","\n","context_vecs = ca(batch)\n","\n","print(context_vecs)\n","print(\"context_vecs.shape:\", context_vecs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SpfjcBIA5CS","executionInfo":{"status":"ok","timestamp":1762401977478,"user_tz":-540,"elapsed":2,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"8e4819dd-9a78-482d-d046-6103cd5593b9"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.5337, -0.1051],\n","         [-0.5323, -0.1080],\n","         [-0.5323, -0.1079],\n","         [-0.5297, -0.1076],\n","         [-0.5311, -0.1066],\n","         [-0.5299, -0.1081]],\n","\n","        [[-0.5337, -0.1051],\n","         [-0.5323, -0.1080],\n","         [-0.5323, -0.1079],\n","         [-0.5297, -0.1076],\n","         [-0.5311, -0.1066],\n","         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n","context_vecs.shape: torch.Size([2, 6, 2])\n"]}]},{"cell_type":"code","source":["class MultiHeadAttentionWrapper(nn.Module):\n","  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n","    super().__init__()\n","    self.heads = nn.ModuleList(\n","        [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)]\n","    )\n","\n","  def forward(self, x):\n","    return torch.cat([head(x) for head in self.heads], dim=-1)\n","\n","torch.manual_seed(123)\n","\n","context_length = batch.shape[1] # 토큰 개수\n","d_in, d_out = 3, 2\n","mha = MultiHeadAttentionWrapper(\n","    d_in, d_out, context_length, 0.0, num_heads=2\n",")\n","\n","context_vecs = mha(batch)\n","\n","print(context_vecs)\n","print(\"context_vecs.shape:\", context_vecs.shape)"],"metadata":{"id":"QuPMiS1gCfTS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762403075404,"user_tz":-540,"elapsed":33,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"2c4eb12c-58d0-446d-9c3c-5325b476117e"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.5337, -0.1051,  0.5085,  0.3508],\n","         [-0.5323, -0.1080,  0.5084,  0.3508],\n","         [-0.5323, -0.1079,  0.5084,  0.3506],\n","         [-0.5297, -0.1076,  0.5074,  0.3471],\n","         [-0.5311, -0.1066,  0.5076,  0.3446],\n","         [-0.5299, -0.1081,  0.5077,  0.3493]],\n","\n","        [[-0.5337, -0.1051,  0.5085,  0.3508],\n","         [-0.5323, -0.1080,  0.5084,  0.3508],\n","         [-0.5323, -0.1079,  0.5084,  0.3506],\n","         [-0.5297, -0.1076,  0.5074,  0.3471],\n","         [-0.5311, -0.1066,  0.5076,  0.3446],\n","         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n","context_vecs.shape: torch.Size([2, 6, 4])\n"]}]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n","    super().__init__()\n","    assert (d_out % num_heads == 0), \"d_out은 num_heads로 나누어 떨어져야 합니다\"\n","\n","    self.d_out = d_out\n","    self.num_heads = num_heads\n","    self.head_dim = d_out // num_heads # 원하는 출력 차원에 맞도록 투영 차원을 낮춘다.\n","\n","    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","    self.out_proj = nn.Linear(d_out, d_out) # Linear 층을 사용해 헤드의 출력을 결합\n","    self.dropout = nn.Dropout(dropout)\n","    self.register_buffer(\n","        \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n","    )\n","\n","  def forward(self, x):\n","    b, num_tokens, d_in = x.shape\n","    # `CausalAttention`과 마찬가지로, 입력의 `num_tokens`가 `context_length`를 넘는 경우 마스크 생성에서 오류가 발생\n","    # 실제로는 forward 메서드에 들어오기 전에 LLM이 입력이 `context_length`를 넘지 않는지 확인하기 때문에 문제가 되지 않는다.\n","\n","    keys = self.W_key(x) # 크기: (b, num_tokens, d_out)\n","    queries = self.W_query(x)\n","    values = self.W_value(x)\n","\n","    # `num_heads` 차원을 추가함으로써 암묵적으로 행렬을 분할한다.\n","    # 그다음 마지막 차원을 `num_heads`에 맞춰 채운다.: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n","    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n","\n","    # 전치: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n","    keys = keys.transpose(1,2)\n","    queries = queries.transpose(1,2)\n","    values = values.transpose(1,2)\n","\n","    # 코잘 마스크로 스케일드 점곱 어텐션(셀프 어텐션)을 계산\n","    attn_scores = queries @ keys.transpose(2,3) # 각 헤드에 대해 점곱을 수행\n","\n","    # 마스크를 불리언 타입으로 만들고 토큰 개수로 마스크를 자른다.\n","    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","\n","    # 마스크를 사용해 어텐션 점수를 채운다.\n","    attn_scores.masked_fill(mask_bool, -torch.inf)\n","\n","    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","    attn_weights = self.dropout(attn_weights)\n","\n","    # 크기: (b, num_tokens, num_heads, head_dim)\n","    context_vec = (attn_weights @ values).transpose(1, 2)\n","\n","    # 헤드를 결합한다. self.d_out = self.num_heads * self.head_dim\n","    context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n","    context_vec = self.out_proj(context_vec) # 투영\n","\n","    return context_vec\n","\n","torch.manual_seed(123)\n","\n","batch_size, context_length, d_in = batch.shape\n","d_out = 2\n","mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n","\n","context_vecs = mha(batch)\n","\n","print(context_vecs)\n","print(\"context_vecs.shape:\", context_vecs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD5xozsBaMQW","executionInfo":{"status":"ok","timestamp":1762405071083,"user_tz":-540,"elapsed":10,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"14ba0642-123f-4184-c9be-1d3e3169b609"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.2595, 0.4014],\n","         [0.2583, 0.4014],\n","         [0.2583, 0.4014],\n","         [0.2575, 0.4031],\n","         [0.2582, 0.4026],\n","         [0.2575, 0.4028]],\n","\n","        [[0.2595, 0.4014],\n","         [0.2583, 0.4014],\n","         [0.2583, 0.4014],\n","         [0.2575, 0.4031],\n","         [0.2582, 0.4026],\n","         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n","context_vecs.shape: torch.Size([2, 6, 2])\n"]}]},{"cell_type":"code","source":["# (b, num_heads, num_tokens, head_dim) = (1,2,3,4)\n","a = torch.tensor([\n","    [\n","        [\n","          [0.2745, 0.6584, 0.2775, 0.8573],\n","          [0.8993, 0.0390, 0.9268, 0.7388],\n","          [0.7179, 0.7058, 0.9156, 0.4340],\n","        ],\n","        [\n","          [0.0772, 0.3565, 0.1479, 0.5331],\n","          [0.4066, 0.2318, 0.4545, 0.9737],\n","          [0.4606, 0.5159, 0.4220, 0.5786],\n","        ],\n","    ]\n","])\n","print(a @ a.transpose(2,3)) # [1,2,3,3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sWyD-uZihzfg","executionInfo":{"status":"ok","timestamp":1762405501535,"user_tz":-540,"elapsed":9,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"d5710c82-cd20-4eb7-c6d1-889f883c3fd4"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1.3208, 1.1631, 1.2879],\n","          [1.1631, 2.2150, 1.8424],\n","          [1.2879, 1.8424, 2.0402]],\n","\n","         [[0.4391, 0.7003, 0.5903],\n","          [0.7003, 1.3737, 1.0620],\n","          [0.5903, 1.0620, 0.9912]]]])\n"]}]},{"cell_type":"code","source":["first_head = a[0, 0, :, :]\n","first_res = first_head @ first_head.T\n","print(\"첫 번째 헤드:\\n\", first_res)\n","\n","second_head = a[0, 1, :, :]\n","second_res = second_head @ second_head.T\n","print(\"\\n두 번째 헤드:\\n\", second_res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdtIPcEAjbia","executionInfo":{"status":"ok","timestamp":1762405665371,"user_tz":-540,"elapsed":9,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"6150f9ef-d4ca-43f3-c23f-17f882ab6b8e"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["첫 번째 헤드:\n"," tensor([[1.3208, 1.1631, 1.2879],\n","        [1.1631, 2.2150, 1.8424],\n","        [1.2879, 1.8424, 2.0402]])\n","\n","두 번째 헤드:\n"," tensor([[0.4391, 0.7003, 0.5903],\n","        [0.7003, 1.3737, 1.0620],\n","        [0.5903, 1.0620, 0.9912]])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"sxMytPo0kCXJ"},"execution_count":null,"outputs":[]}]}