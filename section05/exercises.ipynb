{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOhykBi9gXAOczcZtFbC0LP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpzXNIuHV1wy","executionInfo":{"status":"ok","timestamp":1763190522387,"user_tz":-540,"elapsed":27,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"dba9c329-7ff2-4ccb-ee4d-fb331529b715"},"outputs":[{"output_type":"stream","name":"stdout","text":["numpy 버전: 2.0.2\n","tiktoken 버전: 0.12.0\n","torch 버전: 2.8.0+cu126\n","tensorflow 버전: 2.19.0\n"]}],"source":["from importlib.metadata import version\n","\n","pkgs = [\"numpy\", \"tiktoken\", \"torch\", \"tensorflow\"] # OpenAI의 사전 훈련된 가중치를 위해\n","\n","for p in pkgs:\n","  print(f\"{p} 버전: {version(p)}\")"]},{"cell_type":"markdown","source":["# 연습문제 5.1: 온도 스케일링이 적용된 소프트맥스 점수 및 샘플링 확률"],"metadata":{"id":"QGSo4TuZWE1c"}},{"cell_type":"code","source":["import torch\n","\n","vocab = {\n","    \"closer\": 0,\n","    \"every\": 1,\n","    \"effort\": 2,\n","    \"forward\": 3,\n","    \"inches\": 4,\n","    \"moves\": 5,\n","    \"pizza\": 6,\n","    \"toward\": 7,\n","    \"you\": 8,\n","}\n","\n","inverse_vocab = {v: k for k, v in vocab.items()}\n","\n","# 입력이 \"every effort moves you\"이고\n","# LLM이 다음 토큰을 위해 아래와 같은 로짓을 반환했다 가정\n","next_token_logits = torch.tensor(\n","    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",")\n","\n","def print_sampled_tokens(probas):\n","  torch.manual_seed(123) # 재현가능성을 위한 랜덤 시드\n","  sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n","  sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n","  for i, freq in enumerate(sampled_ids):\n","    print(f\"{freq} x {inverse_vocab[i]}\")\n","\n","def softmax_with_temperature(logits, temperature):\n","  scaled_logits = logits / temperature\n","  return torch.softmax(scaled_logits, dim=0)\n","\n","temperatures = [1, 0.1, 5] # 원본, 높은, 그리고 낮은 온도\n","scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"],"metadata":{"id":"MLJOJUN2WC-0","executionInfo":{"status":"ok","timestamp":1763190892183,"user_tz":-540,"elapsed":85,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["for i, probas in enumerate(scaled_probas):\n","  print(\"\\n\\n온도:\", temperatures[i])\n","  print_sampled_tokens(probas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JjB7KpFSXGMA","executionInfo":{"status":"ok","timestamp":1763190945618,"user_tz":-540,"elapsed":217,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"e9f989c5-5f57-4c25-b3c4-57d822e65be7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","온도: 1\n","73 x closer\n","0 x every\n","0 x effort\n","582 x forward\n","2 x inches\n","0 x moves\n","0 x pizza\n","343 x toward\n","0 x you\n","\n","\n","온도: 0.1\n","0 x closer\n","0 x every\n","0 x effort\n","985 x forward\n","0 x inches\n","0 x moves\n","0 x pizza\n","15 x toward\n","0 x you\n","\n","\n","온도: 5\n","165 x closer\n","75 x every\n","42 x effort\n","239 x forward\n","71 x inches\n","46 x moves\n","32 x pizza\n","227 x toward\n","103 x you\n"]}]},{"cell_type":"code","source":["temp5_idx = 2\n","pizza_idx = 6\n","\n","scaled_probas[temp5_idx][pizza_idx]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnQO_0EoXrVd","executionInfo":{"status":"ok","timestamp":1763191040141,"user_tz":-540,"elapsed":35,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"1bfd0c7c-44ca-4ffa-e79e-c1edb5a51feb"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0430)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# 연습문제 5.2: 다양한 온도 및 top-k 설정\n","\n","## 낮은 top-k 및 온도\n","  - 교육 콘텐츠, 기술 문서 또는 질문 응답, 데이터 분석, 코드 생성 등을 작성할 때 바람직한 덜 무작위적인 결과를 생성한다.\n","\n","## 높은 top-k 및 온도\n","  - 브레인스토밍 작업, 창의적인 글쓰기 등에 더 바람직한 더 다양하고 무작위적인 출력을 생성한다."],"metadata":{"id":"utPMXoOZYFVt"}},{"cell_type":"markdown","source":["# 연습문제 5.3: 디코딩 함수의 결정론적인 동작"],"metadata":{"id":"xF4z3YXPYpRb"}},{"cell_type":"code","source":["!wget https://bit.ly/3HlFmc8 -O previous_chapters.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hW579flDYCcZ","executionInfo":{"status":"ok","timestamp":1763191236675,"user_tz":-540,"elapsed":518,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"b7835bb9-0435-4c3a-ef3d-2d29ddb4a673"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-15 07:20:36--  https://bit.ly/3HlFmc8\n","Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n","Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/previous_chapters.py [following]\n","--2025-11-15 07:20:36--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/previous_chapters.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9905 (9.7K) [text/plain]\n","Saving to: ‘previous_chapters.py’\n","\n","previous_chapters.p 100%[===================>]   9.67K  --.-KB/s    in 0s      \n","\n","2025-11-15 07:20:36 (42.5 MB/s) - ‘previous_chapters.py’ saved [9905/9905]\n","\n"]}]},{"cell_type":"code","source":["!gdown 1Lze7x_4Bd3Sd22sZrCG7cxKOE2wcMKrh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SyBd_fMMYyVj","executionInfo":{"status":"ok","timestamp":1763191327493,"user_tz":-540,"elapsed":15147,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"dfcd646f-d88a-41fd-ed3f-9f4f29614719"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1Lze7x_4Bd3Sd22sZrCG7cxKOE2wcMKrh\n","From (redirected): https://drive.google.com/uc?id=1Lze7x_4Bd3Sd22sZrCG7cxKOE2wcMKrh&confirm=t&uuid=964763a4-952f-4bc1-9929-370787b32b74\n","To: /content/model.pth\n","100% 653M/653M [00:11<00:00, 55.5MB/s]\n"]}]},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257, # 어휘 사전 크기\n","    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n","    \"emb_dim\": 768, # 임베딩 차원\n","    \"n_heads\": 12, # 어텐션 헤드 개수\n","    \"n_layers\": 12, # 층 개수\n","    \"drop_rate\": 0.1, # 드롭아웃 비율\n","    \"qkv_bias\": False, # 쿼리-키-값 생성시 편향 사용 여부\n","}\n","\n","torch.manual_seed(123)\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n","model.eval();"],"metadata":{"id":"UBx_uy2lZE8G","executionInfo":{"status":"ok","timestamp":1763191441172,"user_tz":-540,"elapsed":3518,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!wget https://bit.ly/3FzTX37 -O gpt_generate.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjM5n5e8Zjh6","executionInfo":{"status":"ok","timestamp":1763191467743,"user_tz":-540,"elapsed":320,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"7ec3f3d5-9195-41d5-ecf4-b1bc18573ac7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-15 07:24:27--  https://bit.ly/3FzTX37\n","Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n","Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_generate.py [following]\n","--2025-11-15 07:24:27--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_generate.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11152 (11K) [text/plain]\n","Saving to: ‘gpt_generate.py’\n","\n","gpt_generate.py     100%[===================>]  10.89K  --.-KB/s    in 0s      \n","\n","2025-11-15 07:24:27 (23.9 MB/s) - ‘gpt_generate.py’ saved [11152/11152]\n","\n"]}]},{"cell_type":"code","source":["from gpt_generate import generate, text_to_token_ids, token_ids_to_text\n","from previous_chapters import generate_text_simple"],"metadata":{"id":"Ozd4zEUKZpIu","executionInfo":{"status":"ok","timestamp":1763191560244,"user_tz":-540,"elapsed":4,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# torch.argmax를 사용하는 결정론적 함수\n","\n","start_context = \"Every effort moves you\"\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(start_context, tokenizer),\n","    max_new_tokens=25,\n","    context_size=GPT_CONFIG_124M[\"context_length\"]\n",")\n","\n","print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vo6tQsTXaBdc","executionInfo":{"status":"ok","timestamp":1763191653632,"user_tz":-540,"elapsed":4969,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"2c63937e-3f32-4444-c404-b391a1df9475"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["출력 텍스트:\n"," Every effort moves you?\"\n","\n","\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n","\n","\n"]}]},{"cell_type":"code","source":["# 결정론적 동작: top_k 없음, 온도 스케일링 없음\n","\n","token_ids = generate(\n","    model=model,\n","    idx=text_to_token_ids(start_context, tokenizer),\n","    max_new_tokens=25,\n","    context_size=GPT_CONFIG_124M[\"context_length\"],\n","    top_k=None,\n","    temperature=0.0,\n",")\n","\n","print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fm0hldoFaXCu","executionInfo":{"status":"ok","timestamp":1763191782754,"user_tz":-540,"elapsed":3947,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"8f34e432-bfab-44ec-e27c-482387c2c9d1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["출력 텍스트:\n"," Every effort moves you?\"\n","\n","\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n","\n","\n"]}]},{"cell_type":"markdown","source":["# 연습문제 5.4: 사전 훈련 계속 수행"],"metadata":{"id":"aVllfxTma-IW"}},{"cell_type":"code","source":["!gdown /content/model_and_optimizer.pth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyZSuw-Razt2","executionInfo":{"status":"ok","timestamp":1763192114636,"user_tz":-540,"elapsed":33592,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"38932cc1-fbf6-4044-f726-f5ba59f1c30e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1D_q35z6cqjJTuB3RlD8X7MFmZPF5NI1q\n","From (redirected): https://drive.google.com/uc?id=1D_q35z6cqjJTuB3RlD8X7MFmZPF5NI1q&confirm=t&uuid=0a1ccf1d-5e35-4244-aba3-63ec73b21af9\n","To: /content/model_and_optimizer.pth\n","100% 1.95G/1.95G [00:30<00:00, 63.7MB/s]\n"]}]},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257, # 어휘 사전 크기\n","    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n","    \"emb_dim\": 768, # 임베딩 차원\n","    \"n_heads\": 12, # 어텐션 헤드 개수\n","    \"n_layers\": 12, # 층 개수\n","    \"drop_rate\": 0.1, # 드롭아웃 비율\n","    \"qkv_bias\": False, # 쿼리-키-값 생성시 편향 사용 여부\n","}\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n","\n","model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n","optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iyqNuvHcAmz","executionInfo":{"status":"ok","timestamp":1763193751473,"user_tz":-540,"elapsed":16113,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"988b3fbf-4f1e-403f-e21e-ef2503f7a332"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (tok_emb): Embedding(50257, 768)\n","  (pos_emb): Embedding(256, 768)\n","  (drop_emb): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["import os\n","import urllib.request\n","from previous_chapters import create_dataloader_v1\n","\n","file_path = \"the-verdict.txt\"\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n","\n","if not os.path.exists(file_path):\n","  with urllib.request.urlopen(url) as response:\n","    text_data = response.read().decode('utf-8')\n","  with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","    file.write(text_data)\n","else:\n","  with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    text_data = file.read()\n","\n","# 훈련/검증 비율\n","train_ratio = 0.90\n","split_idx = int(train_ratio * len(text_data))\n","train_data = text_data[:split_idx]\n","val_data = text_data[split_idx:]\n","\n","torch.manual_seed(123)\n","\n","train_loader = create_dataloader_v1(\n","    train_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0,\n",")\n","\n","val_loader = create_dataloader_v1(\n","    val_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0,\n",")"],"metadata":{"id":"YC2AeDaUcvPQ","executionInfo":{"status":"ok","timestamp":1763193849131,"user_tz":-540,"elapsed":167,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["!wget https://bit.ly/4mODn07 -O gpt_train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0zep6Bpfl2z","executionInfo":{"status":"ok","timestamp":1763193071667,"user_tz":-540,"elapsed":335,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"ed959efa-8bd0-4c34-f76a-c0d28a838c8a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-15 07:51:11--  https://bit.ly/4mODn07\n","Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n","Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_train.py [following]\n","--2025-11-15 07:51:11--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_train.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8362 (8.2K) [text/plain]\n","Saving to: ‘gpt_train.py’\n","\n","gpt_train.py        100%[===================>]   8.17K  --.-KB/s    in 0.001s  \n","\n","2025-11-15 07:51:11 (14.0 MB/s) - ‘gpt_train.py’ saved [8362/8362]\n","\n"]}]},{"cell_type":"code","source":["from gpt_train import train_model_simple\n","\n","num_epochs = 1\n","train_losses, val_losses, toekns_seen = train_model_simple(\n","    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs,\n","    eval_freq=5, eval_iter=5, start_context=\"Every effort moves you\", tokenizer=tokenizer\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dQvVA9wfyYg","executionInfo":{"status":"ok","timestamp":1763194068908,"user_tz":-540,"elapsed":143193,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"18d44a0e-0a18-476b-c78a-f944f97b6bc1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Ep 1 (Step 000000): Train loss 0.271, Val loss 6.545\n","Ep 1 (Step 000005): Train loss 0.213, Val loss 6.623\n","Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"]}]},{"cell_type":"markdown","source":["# 연습문제 5.5: 사전 훈련된 모델의 훈련 및 검증 세트 손실"],"metadata":{"id":"tujZeh-yjNlM"}},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257, # 어휘 사전 크기\n","    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n","    \"emb_dim\": 768, # 임베딩 차원\n","    \"n_heads\": 12, # 어텐션 헤드 개수\n","    \"n_layers\": 12, # 층 개수\n","    \"drop_rate\": 0.1, # 드롭아웃 비율\n","    \"qkv_bias\": False, # 쿼리-키-값 생성시 편향 사용 여부\n","}\n","\n","torch.manual_seed(123)\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"27mB_13JjC90","executionInfo":{"status":"ok","timestamp":1763194150069,"user_tz":-540,"elapsed":14,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["!wget https://bit.ly/4kSEn1v -O gpt_download.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9kk1JUlj5vM","executionInfo":{"status":"ok","timestamp":1763194165907,"user_tz":-540,"elapsed":316,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"5f9f5cf1-3639-4ca9-c736-713b43d16357"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-15 08:09:25--  https://bit.ly/4kSEn1v\n","Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n","Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py [following]\n","--2025-11-15 08:09:25--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5972 (5.8K) [text/plain]\n","Saving to: ‘gpt_download.py’\n","\n","gpt_download.py     100%[===================>]   5.83K  --.-KB/s    in 0s      \n","\n","2025-11-15 08:09:25 (41.4 MB/s) - ‘gpt_download.py’ saved [5972/5972]\n","\n"]}]},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","\n","settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WN0JQgm9j9h6","executionInfo":{"status":"ok","timestamp":1763194235407,"user_tz":-540,"elapsed":21978,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"5b68c13c-7a6f-43d1-b921-7ce2548299a2"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 125kiB/s]\n","encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.39MiB/s]\n","hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 58.7kiB/s]\n","model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:19<00:00, 25.4MiB/s]\n","model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.35MiB/s]\n","model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.70MiB/s]\n","vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 3.21MiB/s]\n"]}]},{"cell_type":"code","source":["# 딕셔너리로 모델 설정을 저장\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (124M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (124M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (124M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","# 기본 설정을 특정 값으로 업데이트\n","model_name = \"gpt2-small (124M)\"  # 모델 이름\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\":1024, \"qkv_bias\": True})\n","\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval();"],"metadata":{"id":"0vhNVL-xkJNW","executionInfo":{"status":"ok","timestamp":1763194252713,"user_tz":-540,"elapsed":1964,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from gpt_generate import load_weights_into_gpt\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","load_weights_into_gpt(gpt, params)\n","gpt.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbcxeJzmkSUn","executionInfo":{"status":"ok","timestamp":1763194354179,"user_tz":-540,"elapsed":529,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"4ea1d98f-cbd8-44e7-a813-20c968e03364"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (tok_emb): Embedding(50257, 768)\n","  (pos_emb): Embedding(1024, 768)\n","  (drop_emb): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=True)\n","        (W_key): Linear(in_features=768, out_features=768, bias=True)\n","        (W_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["import os\n","import urllib.request\n","from previous_chapters import create_dataloader_v1\n","\n","file_path = \"the-verdict.txt\"\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n","\n","if not os.path.exists(file_path):\n","  with urllib.request.urlopen(url) as response:\n","    text_data = response.read().decode('utf-8')\n","  with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","    file.write(text_data)\n","else:\n","  with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    text_data = file.read()\n","\n","# 훈련/검증 비율\n","train_ratio = 0.90\n","split_idx = int(train_ratio * len(text_data))\n","train_data = text_data[:split_idx]\n","val_data = text_data[split_idx:]\n","\n","torch.manual_seed(123)\n","\n","train_loader = create_dataloader_v1(\n","    train_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0,\n",")\n","\n","val_loader = create_dataloader_v1(\n","    val_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0,\n",")"],"metadata":{"id":"sm5uPOmUkrcO","executionInfo":{"status":"ok","timestamp":1763194560764,"user_tz":-540,"elapsed":41,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from gpt_train import calc_loss_loader\n","\n","torch.manual_seed(123) # 데이터 로더에서 셔플링을 하므로 재현성을 위해\n","train_loss = calc_loss_loader(train_loader, gpt, device)\n","val_loss = calc_loss_loader(val_loader, gpt, device)\n","\n","print(\"훈련 손실:\", train_loss)\n","print(\"검증 손실:\", val_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mFpFrdeld_x","executionInfo":{"status":"ok","timestamp":1763194662472,"user_tz":-540,"elapsed":31910,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"9567ca75-78d5-49ce-b469-cdfb9a1a1cb6"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 손실: 3.754749059677124\n","검증 손실: 3.5596206188201904\n"]}]},{"cell_type":"code","source":["settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")\n","\n","model_name = \"gpt2-xl (1558M)\"\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\":1024, \"qkv_bias\": True})\n","\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval();\n","\n","load_weights_into_gpt(gpt, params)\n","gpt.to(device)\n","\n","torch.manual_seed(123)\n","train_loss = calc_loss_loader(train_loader, gpt, device)\n","val_loss = calc_loss_loader(val_loader, gpt, device)\n","\n","print(\"훈련 손실:\", train_loss)\n","print(\"검증 손실:\", val_loss)\n","\n","# Colab 무료 버전 작동안함"],"metadata":{"id":"Jprbr78ClvDG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 연습문제 5.6: 더 큰 모델 시도하기\n","\n","settings, params = download_and_load_g\n","pt2(model_size=\"124M\", models_dir=\"gpt2\")\n","model_name = \"gpt2-small (124M)\"\n","\n","settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")\n","model_name = \"gpt2-xl (1558M)\""],"metadata":{"id":"FmOBgOg_milp"}}]}