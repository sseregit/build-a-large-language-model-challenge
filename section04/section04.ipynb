{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKSRKmEswrQ8BjPabcLQXL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCCf7jKpwfr9","executionInfo":{"status":"ok","timestamp":1762414914883,"user_tz":-540,"elapsed":21,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"ed07081c-d7f9-408c-bbe6-fb9eea994f55"},"outputs":[{"output_type":"stream","name":"stdout","text":["맷플롯립 버전: 3.10.0\n","파이토치 버전: 2.8.0+cu126\n","tiktoken 버전: 0.12.0\n"]}],"source":["from importlib.metadata import version\n","\n","print(\"맷플롯립 버전:\", version(\"matplotlib\"))\n","print(\"파이토치 버전:\", version(\"torch\"))\n","print(\"tiktoken 버전:\", version(\"tiktoken\"))"]},{"cell_type":"code","source":["GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257, # 어휘사전 크기\n","    \"context_length\": 1024, # 문맥 길이\n","    \"emb_dim\": 768, # 임베딩 차원\n","    \"n_heads\": 12, # 어텐션 헤드 개수\n","    \"n_layers\": 12, # 층 개수\n","    \"drop_rate\": 0.1, # 드롭아웃 비율\n","    \"qkv_bias\": False, # 쿼리, 키, 값을 만들 때 편향 포함 여부\n","}"],"metadata":{"id":"3_fWQApJHVpt","executionInfo":{"status":"ok","timestamp":1762415406517,"user_tz":-540,"elapsed":3,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class DummyGPTModel(nn.Module):\n","  def __init__(self, cfg):\n","    super().__init__()\n","    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","    # Use a placeholder for TransformerBlock\n","    self.trf_blocks = nn.Sequential(\n","        *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n","    )\n","\n","    # Use a placeholder for LayerNorm\n","    self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n","    self.out_head = nn.Linear(\n","        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n","    )\n","\n","  def forward(self, in_idx):\n","    batch_size, seq_len = in_idx.shape\n","    tok_embeds = self.tok_emb(in_idx)\n","    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","    x = tok_embeds + pos_embeds\n","    x = self.drop_emb(x)\n","    x = self.trf_blocks(x)\n","    x = self.final_norm(x)\n","    logits = self.out_head(x)\n","    return logits\n","\n","class DummyTransformerBlock(nn.Module):\n","  def __init__(self, cfg):\n","    super().__init__()\n","    # 더미클래스\n","\n","  def forward(self, x):\n","    # 이 블록은 아무것도 하지 않고 입력을 그냥 반환합니다.\n","    return x\n","\n","class DummyLayerNorm(nn.Module):\n","  def __init__(self, normalized_shape, eps=1e-5):\n","    super().__init__()\n","    # 층 정규화 인터페이스를 흉내내기 위한 매개변수\n","\n","  def forward(self, x):\n","    # 이 블록은 아무것도 하지 않고 입력을 그냥 반환한다.\n","    return x"],"metadata":{"id":"EXYWKffNJOzP","executionInfo":{"status":"ok","timestamp":1762416736094,"user_tz":-540,"elapsed":5,"user":{"displayName":"장연식","userId":"03599627759361599230"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import tiktoken\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","batch = []\n","\n","txt1 = \"Every effort moves you\"\n","txt2 = \"Every day holds a\"\n","\n","batch.append(torch.tensor(tokenizer.encode(txt1)))\n","batch.append(torch.tensor(tokenizer.encode(txt2)))\n","batch = torch.stack(batch, dim=0)\n","print(batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ss4Gl2aMy5P","executionInfo":{"status":"ok","timestamp":1762416738852,"user_tz":-540,"elapsed":6,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"fa30ace2-f6d2-4c06-a625-25b0ffeab43e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[6109, 3626, 6100,  345],\n","        [6109, 1110, 6622,  257]])\n"]}]},{"cell_type":"code","source":["torch.manual_seed(123)\n","model = DummyGPTModel(GPT_CONFIG_124M)\n","\n","logits = model(batch)\n","print(\"출력 크기:\", logits.shape)\n","print(logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INBJZg4XNnrn","executionInfo":{"status":"ok","timestamp":1762416742429,"user_tz":-540,"elapsed":1550,"user":{"displayName":"장연식","userId":"03599627759361599230"}},"outputId":"c5ce6d03-5839-4a45-da8d-f772245cc12a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["출력 크기: torch.Size([2, 4, 50257])\n","tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n","         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n","         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n","         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n","\n","        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n","         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n","         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n","         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n","       grad_fn=<UnsafeViewBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zwa-wjNvN_nW"},"execution_count":null,"outputs":[]}]}